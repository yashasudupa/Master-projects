{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 40 and 20 for 'MatMul_61' (op: 'MatMul') with input shapes: [?,40], [20,26].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    685\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[1;32m    687\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 40 and 20 for 'MatMul_61' (op: 'MatMul') with input shapes: [?,40], [20,26].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-fecd57818c59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefineNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;31m# check also implementations of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-fecd57818c59>\u001b[0m in \u001b[0;36mdefineNN\u001b[0;34m(x, lay)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;31m# Output fully connected layer with a neuron for each class: logits ready for softmax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;31m#y = tf.nn.softmax(tf.matmul(layer_1, weights['out']) + biases['out'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'out'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbiases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'out'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   1889\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m       return gen_math_ops._mat_mul(\n\u001b[0;32m-> 1891\u001b[0;31m           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[1;32m   1892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36m_mat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   2435\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m   2436\u001b[0m         \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2437\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   2438\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2439\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2956\u001b[0m         op_def=op_def)\n\u001b[1;32m   2957\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2958\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2959\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2960\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2207\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2209\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2210\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2211\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2158\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2159\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2161\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, require_shape_fn)\u001b[0m\n\u001b[1;32m    625\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    626\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m                                   require_shape_fn)\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    689\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 40 and 20 for 'MatMul_61' (op: 'MatMul') with input shapes: [?,40], [20,26]."
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.preprocessing\n",
    "import os \n",
    "from math import sqrt \n",
    "\n",
    "# plt.close('all')  # if you like\n",
    "\n",
    "# load dataset\n",
    "with open('isolet_crop_train.pkl', 'rb') as f:\n",
    "    train_data = pkl.load(f)\n",
    "with open('isolet_crop_test.pkl', 'rb') as f:\n",
    "    test_data = pkl.load(f)\n",
    "\n",
    "X_alltrain, Y_alltrain = train_data\n",
    "X_test, Y_test = test_data\n",
    "\n",
    "def onehotK(labels):\n",
    "    label_binarizer = sklearn.preprocessing.LabelBinarizer()\n",
    "    label_binarizer.fit(range(max(labels)))\n",
    "    labels = label_binarizer.transform(labels)\n",
    "    return labels\n",
    "\n",
    "# convert labels \n",
    "Y_alltrain = onehotK(Y_alltrain)\n",
    "Y_test = onehotK(Y_test)\n",
    "\n",
    "# split the datasets: big training set into training and validation \n",
    "x_train,x_allval,y_train,y_allval = train_test_split(X_alltrain,Y_alltrain, test_size = 0.3,stratify = Y_alltrain)\n",
    "# split validation data into smaller validation and early stopping\n",
    "x_val,x_estop,y_val,y_estop = train_test_split(x_allval,y_allval, test_size = 0.5,stratify = y_allval)\n",
    "\n",
    "# normalize features to zero mean and unit variance\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train) # fit scaler and apply transformation\n",
    "x_estop = scaler.transform(x_estop) # apply same transformation to test data\n",
    "x_val = scaler.transform(x_val) # apply same transformation to test data\n",
    "\n",
    "# for a) \n",
    "xtrain = x_train\n",
    "ytrain = y_train\n",
    "\n",
    "nHiddenLayers = 1 # number of hidden layers\n",
    "n_hidden_1 = 20 # number of nodes in each layer\n",
    "\n",
    "# from data\n",
    "nSamples,nFeat = xtrain.shape\n",
    "nClasses = ytrain.shape[1]\n",
    "nInput = nClasses\n",
    "nOutput = nClasses\n",
    "\n",
    "lay = 4;\n",
    "opt = 3; # which training algorithm\n",
    "\n",
    "# placeholders for data and labels\n",
    "x = tf.placeholder(\"float\",shape = (None,nFeat))\n",
    "y_true = tf.placeholder(\"float\",shape=(None,nClasses))\n",
    "    \n",
    "# initialize and store layers weight & bias for 1 layer scenario\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.truncated_normal([nFeat, n_hidden_1], stddev=1.0 / sqrt(float(nFeat))),trainable=True),\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden_1, nOutput],stddev=1.0 / sqrt(float(n_hidden_1))),trainable=True)\n",
    "}\n",
    "\n",
    "if lay == 3: # relu case\n",
    "    biases = {\n",
    "        'b1': tf.Variable(tf.constant(0.1,shape=[n_hidden_1]),trainable=True),\n",
    "        'out': tf.Variable(tf.constant(0.1,shape=[nOutput]),trainable=True)\n",
    "    }\n",
    "else:   \n",
    "    biases = {\n",
    "        'b1': tf.Variable(tf.zeros([n_hidden_1]),trainable=True),\n",
    "        'out': tf.Variable(tf.zeros([nOutput]),trainable=True)\n",
    "    }\n",
    "\n",
    "# define the network\n",
    "def defineNN(x,lay):\n",
    "    \n",
    "    if lay == 1:\n",
    "        layer_1 = tf.nn.sigmoid((tf.matmul(x, weights['h1'])+ biases['b1']))\n",
    "    elif lay == 2:\n",
    "        layer_1 = tf.nn.tanh((tf.matmul(x, weights['h1'])+ biases['b1']))\n",
    "    elif lay ==3:\n",
    "        layer_1 = tf.nn.relu((tf.matmul(x, weights['h1'])+ biases['b1']))\n",
    "    elif lay == 4:\n",
    "        layer_1 = tf.nn.crelu((tf.matmul(x, weights['h1'])+ biases['b1']))\n",
    "    elif lay == 5:\n",
    "        layer_1 = tf.nn.swish((tf.matmul(x, weights['h1'])+ biases['b1']))\n",
    "    \n",
    "    # Hidden fully connected layer\n",
    "    #layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    # Output fully connected layer with a neuron for each class: logits ready for softmax \n",
    "    #y = tf.nn.softmax(tf.matmul(layer_1, weights['out']) + biases['out'])\n",
    "    y = (tf.matmul(layer_1, weights['out']) + biases['out'])\n",
    "    \n",
    "    return y\n",
    "\n",
    "y = defineNN(x,lay)\n",
    "\n",
    "# check also implementations of \n",
    "# tf.nn.softmax_cross_entropy_with_logits\n",
    "# tf.nn.sparse_softmax_cross_entropy_with_logits\n",
    "\n",
    "with tf.name_scope('cross_entropy'):\n",
    "    ce = tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=y)\n",
    "    cost = tf.reduce_mean(ce)\n",
    "    tf.summary.scalar('cross_entropy',cost)\n",
    "with tf.name_scope('train'):\n",
    "    if opt == 1:\n",
    "        if lay == 3:\n",
    "            lr = 0.001 # learning rate     \n",
    "        else:\n",
    "            lr = 0.5\n",
    "        train_step = tf.train.GradientDescentOptimizer(lr).minimize(cost) # learning rate = 0.001\n",
    "    elif opt ==2:\n",
    "        lr = 0.001 # learning rate        \n",
    "        train_step = tf.train.RMSPropOptimizer(lr).minimize(cost)\n",
    "    elif opt ==3: \n",
    "        lr = 0.001 # learning rate                \n",
    "        train_step = tf.train.AdamOptimizer(lr).minimize(cost)\n",
    "with tf.name_scope('misclassification'):\n",
    "    correct = tf.equal(tf.argmax(y,1),tf.argmax(y_true,1))    \n",
    "    misclassification = (1-tf.reduce_mean(tf.cast(correct,tf.float64)))*100\n",
    "    tf.summary.scalar('misclassification',misclassification)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    ## Actual training step\n",
    "    # init variables to start from scratch\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # create list to monitor how error decreases\n",
    "    estop_error_list = []\n",
    "    train_error_list = []\n",
    "    estop_mcr_list = []\n",
    "    train_mcr_list = []\n",
    "\n",
    "    # Create minibtaches to train faster\n",
    "    k_batch = 40 # size of minibatch in n. examples\n",
    "    xbatch_list = np.array_split(xtrain, k_batch)\n",
    "    ybatch_list = np.array_split(ytrain, k_batch)\n",
    "\n",
    "    a = 0\n",
    "    for k in range(500):\n",
    "        # run training steps in minibatches \n",
    "        for x_minibatch,labels_minibatch in zip(xbatch_list,ybatch_list):\n",
    "            sess.run(train_step, feed_dict={x: x_minibatch, y_true:labels_minibatch})\n",
    "        \n",
    "        ww = sess.run(weights, feed_dict={x: xtrain, y_true: ytrain})\n",
    "\n",
    "        train_err = sess.run(cost, feed_dict={x: xtrain, y_true: ytrain})\n",
    "        estop_err = sess.run(cost, feed_dict={x: x_estop, y_true: y_estop})\n",
    "    \n",
    "        # Compute the mcr over the whole dataset\n",
    "        train_mcr = sess.run(misclassification, feed_dict={x: xtrain, y_true: ytrain})\n",
    "        estop_mcr = sess.run(misclassification, feed_dict={x: x_estop, y_true: y_estop})\n",
    "    \n",
    "        # Put cee and mcr into the lists\n",
    "        estop_error_list.append(estop_err)\n",
    "        train_error_list.append(train_err)\n",
    "        estop_mcr_list.append(estop_mcr)\n",
    "        train_mcr_list.append(train_mcr)\n",
    "        \n",
    "        #if opt == 1: # criteria for Stochastic GD\n",
    "            #if k > 1 and (val_error_list[-1]-val_error_list[-2])>-1e-3:\n",
    "                #print(\"Converged at epoch %d with misclassification rate of %.2f %%\" % (k,train_mcr_list[-1]))\n",
    "                #stopping = k\n",
    "                #break\n",
    "        #else: # criteria for RMSProp and ADAM\n",
    "        if k > 1 and (estop_error_list[-1]-estop_error_list[-2] > 0) and a == 0:\n",
    "            a=1\n",
    "            print(\"Converged at epoch %d with misclassification rate of %.2f on E validation set %%\" % (k-1,estop_mcr_list[-1]))\n",
    "            validation_mcr = sess.run(misclassification, feed_dict={x: x_val, y_true: y_val})\n",
    "            print(\"                           misclassification rate of %.2f on V validation set %%\" % (validation_mcr))            \n",
    "            break\n",
    "\n",
    "sess.close()\n",
    "\n",
    "fig,ax_list = plt.subplots(1,2)\n",
    "ax_list[0].plot(train_error_list, color='blue', label='training', lw=2)\n",
    "ax_list[0].plot(estop_error_list, color='green', label='test', lw=2)\n",
    "ax_list[1].plot(train_mcr_list, color='blue', label='training', lw=2)\n",
    "ax_list[1].plot(estop_mcr_list, color='green', label='test', lw=2)\n",
    "\n",
    "ax_list[0].set_title('Cross-entropy')\n",
    "ax_list[0].set_xlabel('Training epoch')\n",
    "ax_list[0].set_ylabel('Cross-entropy')\n",
    "ax_list[1].set_title('Misclassification Rate (%)')\n",
    "ax_list[1].set_xlabel('Training epoch')\n",
    "ax_list[1].set_ylabel('Misclassification Rate (%)')\n",
    "ax_list[0].legend(loc='best')\n",
    "ax_list[1].legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Re-train \n",
    "# Use all train + estop data; stop at iteration; test on validation set \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(ww['h1'])\n",
    "np.shape(ww['h1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
